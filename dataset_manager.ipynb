{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07e4263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be4bb93",
   "metadata": {},
   "source": [
    "# Create data package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d3d075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_KEEL_dataset(path):\n",
    "\twith open(path, 'r') as fh:\n",
    "\t\tlines = fh.readlines()\n",
    "\t\n",
    "\trelation_name = ''\n",
    "\tattributes = []\n",
    "\tattribute_types = {}\n",
    "\tdata_lines = []\n",
    "\tin_data_section = False\n",
    "\n",
    "\tfor line in lines:\n",
    "\t\tline = line.strip().lower()\n",
    "\t\tif line.startswith('@relation'):\n",
    "\t\t\trelation_name = line.split()[1]\n",
    "\t\telif line.startswith('@attribute'):\n",
    "\t\t\t# Match attribute lines with types and optional ranges or enumerations\n",
    "\t\t\tmatch = re.match(r'@attribute\\s+(\\w+)\\s+(\\w+)(?:\\s+\\[.*?\\])?', line)\n",
    "\t\t\tif match:\n",
    "\t\t\t\tattr_name, attr_type = match.groups()\n",
    "\t\t\t\tattributes.append(attr_name)\n",
    "\t\t\t\tattribute_types[attr_name] = attr_type\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Match attribute lines with enumerated types\n",
    "\t\t\t\tmatch_enum = re.match(r'@attribute\\s+(\\w+)\\s+\\{.*?\\}', line)\n",
    "\t\t\t\tif match_enum:\n",
    "\t\t\t\t\tattr_name = match_enum.group(1)\n",
    "\t\t\t\t\tattributes.append(attr_name)\n",
    "\t\t\t\t\tattribute_types[attr_name] = 'categorical'\n",
    "\t\telif line.startswith('@data'):\n",
    "\t\t\tin_data_section = True\n",
    "\t\telif in_data_section:\n",
    "\t\t\tif line and not line.startswith('@'):\n",
    "\t\t\t\tdata_lines.append(line)\n",
    "\n",
    "\t# Create DataFrame from data lines\n",
    "\tdata_str = '\\n'.join(data_lines)\n",
    "\tdf = pd.read_csv(StringIO(data_str), header=None, names=attributes)\n",
    "\n",
    "\treturn df, attribute_types\n",
    "\n",
    "def create_KEEL_preprocessor_pipeline(attributes):\n",
    "\ttype_mappings = {}\n",
    "\tcategorical_features = []\n",
    "\tnumerical_features = []\n",
    "\n",
    "\tfor column in attributes:\n",
    "\t\tif column != \"Class\" and attributes[column] != 'categorical':\n",
    "\t\t\tnumerical_features.append(column)\n",
    "\t\telif column != \"Class\" and attributes[column] == 'categorical':\n",
    "\t\t\tcategorical_features.append(column)\n",
    "\n",
    "\tcategorical_transformer = Pipeline(steps=[\n",
    "\t\t('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "\t\t('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "\t])\n",
    "\tnumerical_transformer = Pipeline(steps=[\n",
    "\t\t('imputer', SimpleImputer(strategy='mean')),\n",
    "\t\t('scaler', StandardScaler())\n",
    "\t])\n",
    "\t\t\t\n",
    "\ttransformer_steps = []\n",
    "\tif numerical_features != []:\n",
    "\t\ttransformer_steps.append(\n",
    "\t\t\t('num', numerical_transformer, numerical_features)\n",
    "\t\t)\n",
    "\tif 'Categorical' in type_mappings:\n",
    "\t\ttransformer_steps.append(\n",
    "\t\t\t('cat', categorical_transformer, categorical_features)\n",
    "\t\t)\n",
    "\tpreprocessor = ColumnTransformer(\n",
    "\t\ttransformers=transformer_steps\n",
    "\t)\n",
    "\tpipeline = Pipeline(steps=[\n",
    "\t\t('preprocessor', preprocessor)\n",
    "\t])\n",
    "\n",
    "\treturn pipeline\n",
    "\n",
    "def prepare_splits(x, y):\n",
    "\ttrain_split = StratifiedShuffleSplit(\n",
    "\t\tn_splits=31, \n",
    "\t\ttest_size=0.5\n",
    "\t)\n",
    "\tsplits = []\n",
    "\tfor train_idx, temp_idx in train_split.split(x, y):\n",
    "\t\ttest_split = StratifiedShuffleSplit(\n",
    "\t\t\tn_splits=1, \n",
    "\t\t\ttest_size=0.5\n",
    "\t\t)\n",
    "\t\ttest_idx, validation_idx = next(test_split.split(x[temp_idx], y[temp_idx]))\n",
    "\n",
    "\t\tvalidation_idx = temp_idx[validation_idx]\n",
    "\t\ttest_idx = temp_idx[test_idx]\n",
    "\t\t\n",
    "\t\tsplits.append((train_idx, validation_idx, test_idx))\n",
    "\treturn splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b324f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mapper = {}\n",
    "for dat_file in Path('datasets').rglob('*.dat'):\n",
    "\n",
    "\tif \"MACOSX\" in str(dat_file):\n",
    "\t\tcontinue\n",
    "\n",
    "\tname = str(dat_file.name).replace(\".dat\", \"\")\n",
    "\n",
    "\tdataset, attributes = load_KEEL_dataset(dat_file)\n",
    "\n",
    "\ty = dataset['class']\t\n",
    "\traw_X = dataset.drop(columns=['class'])\n",
    "\t\n",
    "\tlabel_encoder = LabelEncoder()\n",
    "\ty = label_encoder.fit_transform(y)\n",
    "\n",
    "\tpipeline = create_KEEL_preprocessor_pipeline(attributes)\n",
    "\n",
    "\tpipeline.fit(raw_X, y)\n",
    "\tX = pipeline.transform(raw_X)\n",
    "\tlabel_encoder = LabelEncoder()\n",
    "\ty = label_encoder.fit_transform(y)\n",
    "\n",
    "\tfor c, (train_idx, validation_idx, test_idx) in enumerate(prepare_splits(X, y)):\n",
    "\t\tdata_mapper[f\"{c}_{name}\"] = {\n",
    "\t\t\t'Dataset': name,\n",
    "\t\t\t'Version': c,\n",
    "\t\t\t'x_train': X[train_idx],\n",
    "\t\t\t'y_train': y[train_idx],\n",
    "\t\t\t'x_validation': X[validation_idx],\n",
    "\t\t\t'y_validation': y[validation_idx],\n",
    "\t\t\t'x_test': X[test_idx],\n",
    "\t\t\t'y_test': y[test_idx],\n",
    "\t\t}\n",
    "\n",
    "with open('data.pickle', 'wb') as fh:\n",
    "\tpickle.dump(data_mapper, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60353a5d",
   "metadata": {},
   "source": [
    "# Inspect data package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f167925",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pickle', 'rb') as fh:\n",
    "\tdata_mapper = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71b150b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_by_dataset_name = {}\n",
    "for data_key in data_mapper:\n",
    "\tsegments = data_key.split('_')\n",
    "\tsplit_num = segments[0]\n",
    "\tdataset_name = '_'.join(segments[1:])\n",
    "\t\n",
    "\tif dataset_name not in split_by_dataset_name:\n",
    "\t\tsplit_by_dataset_name[dataset_name] = []\n",
    "\t\n",
    "\tsplit_by_dataset_name[dataset_name].append(data_key)\n",
    "\n",
    "pd.DataFrame.from_records(split_by_dataset_name).to_csv('data_splits.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba65b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = pd.read_csv('data_splits.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
