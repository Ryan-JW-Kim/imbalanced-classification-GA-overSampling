{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36534102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import ConditionalVAE\n",
    "from model.dataset import TabularDataset\n",
    "from model.utils.visualization import PCA_plot, PCA_plot_rare_on_top\n",
    "from model.utils.optimization import *\n",
    "from model.utils.analysis import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "from matplotlib.cm import get_cmap\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, balanced_accuracy_score\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from imblearn.over_sampling import (\n",
    "\tSMOTE,\n",
    "\tADASYN,\n",
    "\tRandomOverSampler,\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def mask_features(x, min_mask: int = 1, max_mask: int = 3):\n",
    "\tx_masked = x.clone()\n",
    "\tfor i in range(x.size(0)):\n",
    "\t\tk = torch.randint(min_mask, max_mask + 1, (1,)).item()\n",
    "\t\tidx = torch.randperm(x.size(1))[:k]\n",
    "\t\tx_masked[i, idx] = 0\n",
    "\treturn x_masked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39652c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pickle', 'rb') as fh:\n",
    "\tdata_mapper = pickle.load(fh)\n",
    "splits = pd.read_csv('data_splits.csv')\n",
    "\n",
    "data_keys = []\n",
    "for split_name in splits:\n",
    "\tfor idx in range(31):\n",
    "\t\tdata_keys.append(f\"{idx}_{split_name}\")\n",
    "\n",
    "def KNN_analysis(x, y, x_test, y_test):\n",
    "\tmodel = KNeighborsClassifier(n_neighbors=5)\n",
    "\tmodel.fit(x, y)\n",
    "\ty_pred = model.predict(x_test)\n",
    "\n",
    "\tauc = roc_auc_score(y_test, y_pred)\n",
    "\tacc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\tcounts = pd.DataFrame(y).value_counts()\n",
    "\tir = counts.max()/counts.min()\n",
    "\n",
    "\treturn ir, acc, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb63bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_abalone-17_vs_7-8-9-10\n",
      "(np.float64(38.86363636363637), 0.9777397260273972, np.float64(0.5357142857142857))\n",
      "(np.float64(1.0), 0.9434931506849316, np.float64(0.7271929824561404))\n",
      "(np.float64(1.0), 0.910958904109589, np.float64(0.7453634085213032))\n",
      "(np.float64(1.0058823529411764), 0.916095890410959, np.float64(0.7828320802005012))\n"
     ]
    }
   ],
   "source": [
    "def train_model(X, Y):\n",
    "\tminority_label = get_minority_label(Y)\n",
    "\tnum_features = X[0].shape[0]\n",
    "\tnearest_neighbours = NearestNeighbors(n_neighbors=5, metric=\"euclidean\").fit(X)\n",
    "\tdist, idx = nearest_neighbours.kneighbors(X)\n",
    "\tdist = dist[:, 1:]\n",
    "\tidx  = idx[:, 1:]\n",
    "\n",
    "\tknn_features = [X[row_idx] for row_idx in idx]\n",
    "\tknn_labels = [X[row_idx] for row_idx in idx]\n",
    "\n",
    "\tinput_set, recon_set, labels = [], [], []\n",
    "\tfor s_idx, sample in enumerate(X):\n",
    "\t\tfor n_idx, neighbouring_sample in enumerate(knn_features[s_idx]):\n",
    "\t\t\tif Y[s_idx] == knn_labels[s_idx][n_idx]:\n",
    "\t\t\t\tinput_set.append(sample)\n",
    "\t\t\t\trecon_set.append(neighbouring_sample)\n",
    "\t\t\t\tlabels.append(Y[s_idx])\n",
    "\n",
    "\n",
    "\tcvae = ConditionalVAE(\n",
    "\t\tinput_dim=num_features, \n",
    "\t\th1=num_features + (num_features//2), \n",
    "\t\th2=num_features * 2, \n",
    "\t\tlatent_dim=20\n",
    "\t\t).to(device)\n",
    "\n",
    "\tepochs = 900\n",
    "\tbatch_size = 32\n",
    "\tlr = 1e-3\n",
    "\tbeta = 0.8\n",
    "\n",
    "\tdata = TabularDataset(X, X, Y)\n",
    "\tloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\tcvae.train()\n",
    "\topt = optim.Adam(cvae.parameters(), lr=lr)\n",
    "\tfor epoch in range(1, epochs + 1):\n",
    "\t\tfor encode_in, decode_comp, label in loader:\n",
    "\t\t\txb = encode_in.float().to(device)\n",
    "\t\t\tyb = decode_comp.float().to(device)\n",
    "\t\t\tlabel = label.float().to(device)\n",
    "\t\t\t# xb_mask = mask_features(xb)\n",
    "\t\t\trecon, mu, logvar = cvae(xb, label)\n",
    "\t\t\trecon_loss = nn.MSELoss(reduction='sum')(recon, xb)\n",
    "\t\t\tkl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\t\t\tloss = (recon_loss + beta * kl_div) / xb.size(0)   # per-batch average\n",
    "\n",
    "\t\t\topt.zero_grad()\n",
    "\t\t\tloss.backward()\n",
    "\t\t\topt.step()\n",
    "\n",
    "\tepochs = 400\n",
    "\n",
    "\tdata = TabularDataset(\n",
    "\t\tnp.array(input_set), \n",
    "\t\tnp.array(recon_set), \n",
    "\t\tnp.array(labels)\n",
    "\t)\n",
    "\tloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\tcvae.train()\n",
    "\topt = optim.Adam(cvae.parameters(), lr=lr)\n",
    "\tfor epoch in range(1, epochs + 1):\n",
    "\t\tfor encode_in, decode_comp, label in loader:\n",
    "\t\t\txb = encode_in.float().to(device)\n",
    "\t\t\txb_masked = mask_features(xb)\n",
    "\t\t\tyb = decode_comp.float().to(device)\n",
    "\t\t\tlabel = label.float().to(device)\n",
    "\t\t\trecon, mu, logvar = cvae(xb_masked, label)\n",
    "\t\t\trecon_loss = nn.MSELoss(reduction='sum')(recon, yb)\n",
    "\t\t\tkl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\t\t\tloss = (recon_loss + beta * kl_div) / xb.size(0)   # per-batch average\n",
    "\n",
    "\t\t\topt.zero_grad()\n",
    "\t\t\tloss.backward()\n",
    "\t\t\topt.step()\n",
    "\n",
    "\treturn cvae\n",
    "\n",
    "for dataset_name in splits:\n",
    "\tif dataset_name in ['cleveland-0_vs_4', 'wisconsin']: continue\n",
    "\tif any(flag in dataset_name for flag in ['winequality', 'yeast']): continue\n",
    "\t\n",
    "\tfor idx in range(31):\n",
    "\t\tdata_key = f\"{idx}_{dataset_name}\"\n",
    "\t\tprint(data_key)\n",
    "\t\t\n",
    "\t\tX = np.concatenate((data_mapper[data_key]['x_train'], data_mapper[data_key]['x_validation']), axis=0)\n",
    "\t\tY = np.concatenate((data_mapper[data_key]['y_train'], data_mapper[data_key]['y_validation']), axis=0)\n",
    "\t\t\n",
    "\t\t# model = train_model(X, Y)\n",
    "\t\t# with open(f'model_types/base_{data_key}.pkl') as fh: pickle.dump(model, fh)\n",
    "\n",
    "\t\tros_x, ros_y = RandomOverSampler().fit_resample(X, Y)\t\n",
    "\t\tmodel = train_model(X, Y)\n",
    "\t\twith open(f'model_types/ros_{data_key}.pkl') as fh: pickle.dump(model, fh)\n",
    "\n",
    "\t\tsmote_x, smote_y = SMOTE().fit_resample(X, Y)\t\n",
    "\t\tmodel = train_model(X, Y)\n",
    "\t\twith open(f'model_types/smote_{data_key}.pkl') as fh: pickle.dump(model, fh)\n",
    "\n",
    "\t\tadasyn_x, adasyn_y = ADASYN().fit_resample(X, Y)\t\n",
    "\t\tmodel = train_model(X, Y)\n",
    "\t\twith open(f'model_types/adasyn_{data_key}.pkl') as fh: pickle.dump(model, fh)\n",
    "\n",
    "\n",
    "\t\t# if os.path.exists(f'results_new/{data_key}.pkl'): continue\n",
    "\t\t\n",
    "\t\tfor _ in range(3):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tpass\n",
    "\t\t\t\t# torch.save(model.state_dict(), f\"models/{data_key}.mdl\")\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tpass\n",
    "\t\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
